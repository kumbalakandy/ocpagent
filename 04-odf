oc label node <node1> <node2> <node3> cluster.ocs.openshift.io/openshift-storage=''


oc adm new-project openshift-local-storage

oc label ns/openshift-local-storage openshift.io/cluster-monitoring=true
oc annotate namespace openshift-local-storage openshift.io/node-selector=''

apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: local-operator-group
  namespace: openshift-local-storage
spec:
  targetNamespaces:
    - openshift-local-storage
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: local-storage-operator
  namespace: openshift-local-storage
spec:
  channel: stable
  installPlanApproval: Automatic 
  name: local-storage-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  config:
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    tolerations:
      - key: "node-role.kubernetes.io/infra"
        operator: "Exists"
        effect: "NoSchedule"

-------
oc label namespace/openshift-storage openshift.io/cluster-monitoring=true

apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-storage
  namespace: openshift-storage
spec:
  targetNamespaces:
    - openshift-storage

apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: odf-operator
  namespace: openshift-storage
spec:
  channel: "stable-4.16"
  installPlanApproval: Automatic
  name: odf-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace

oc get csvs -n openshift-local-storage
oc get pods -n openshift-local-storage

---
apiVersion: local.storage.openshift.io/v1alpha1
kind: LocalVolumeSet
metadata:
  name: lvs-cache
  namespace: openshift-local-storage
spec:
  storageClassName: local-cache-sc
  volumeMode: Filesystem
  fsType: xfs
  deviceInclusionSpec:
    deviceTypes: ["disk"]
    minSize: 1800Gi
    deviceMechanicalProperties: ["NonRotational"]  # if SSDs
  maxDeviceCount: 2
  nodeSelector:
    nodeSelectorTerms:
    - matchExpressions:
      - key: cluster.ocs.openshift.io/openshift-storage
        operator: Exists
---
apiVersion: local.storage.openshift.io/v1alpha1
kind: LocalVolumeSet
metadata:
  name: lvs-odf
  namespace: openshift-local-storage
spec:
  storageClassName: localblock-odf
  volumeMode: Block
  deviceInclusionSpec:
    deviceTypes: ["disk"]
    minSize: 1800Gi
    deviceMechanicalProperties: ["NonRotational"]
  maxDeviceCount: 4
  nodeSelector:
    nodeSelectorTerms:
    - matchExpressions:
      - key: cluster.ocs.openshift.io/openshift-storage
        operator: Exists


apiVersion: "local.storage.openshift.io/v1"
kind: "LocalVolume"
metadata:
  name: "local-cache-storage"
  namespace: "openshift-local-storage" 
spec:
  nodeSelector: 
    nodeSelectorTerms:
    - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - master01.pure-agent1.kodevirtual.com
          - master02.pure-agent1.kodevirtual.com
          - master03.pure-agent1.kodevirtual.com
  storageClassDevices:
    - storageClassName: "local-sc" 
      forceWipeDevicesAndDestroyAllData: false 
      volumeMode: Filesystem 
      fsType: xfs 
      devicePaths: 
        - /dev/sdb
        - /dev/sdc



sample
------
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: local-sc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: lvs-fs-sc
  volumeMode: Filesystem


apiVersion: v1
kind: Pod
metadata:
  name: lvs-pod
  namespace: test
spec:
  containers:
  - name: ocs
    image: quay.io/centos/centos
    ports:
      - containerPort: 80
        name: "http-server"
    command: ["/bin/bash", "-c", "sleep 2000000000"]
    volumeMounts:
      - mountPath: /data
        name: lvs-fs-pv
  volumes:
    - name: lvs-fs-pv
      persistentVolumeClaim:
        claimName: lvs-fs-pvc


oc get pv --selector storage.openshift.com/owner-name=local-cache-storage

oc get pv


apiVersion: "local.storage.openshift.io/v1"
kind: "LocalVolume"
metadata:
  name: "m01-local-cache-storage"
  namespace: "openshift-local-storage" 
spec:
  nodeSelector: 
    nodeSelectorTerms:
    - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - m01.aic.kodevirtual.com
  storageClassDevices:
    - storageClassName: "local-sc" 
      forceWipeDevicesAndDestroyAllData: false 
      volumeMode: Block
      devicePaths: 
        - /dev/disk/by-id/wwn-0x6000c29041d23ef4071e39975cde2e72
        - /dev/disk/by-id/wwn-0x6000c2924eb213a6f14f9c6de3b6e6db
        - /dev/disk/by-id/wwn-0x6000c298bf37c57e4ad97954e080d9be

apiVersion: "local.storage.openshift.io/v1"
kind: "LocalVolume"
metadata:
  name: "m02-local-cache-storage"
  namespace: "openshift-local-storage" 
spec:
  nodeSelector: 
    nodeSelectorTerms:
    - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - m02.aic.kodevirtual.com
  storageClassDevices:
    - storageClassName: "local-sc" 
      forceWipeDevicesAndDestroyAllData: false 
      volumeMode: Block
      devicePaths: 
        - /dev/disk/by-id/wwn-0x6000c292465adf11bbe5493ffe37c593
        - /dev/disk/by-id/wwn-0x6000c290b7a72979a3852cc022664dc0
        - /dev/disk/by-id/wwn-0x6000c29ce27a8a4e8a2ad965d5a4a2ab

apiVersion: "local.storage.openshift.io/v1"
kind: "LocalVolume"
metadata:
  name: "m03-local-cache-storage"
  namespace: "openshift-local-storage" 
spec:
  nodeSelector: 
    nodeSelectorTerms:
    - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - m03.aic.kodevirtual.com
  storageClassDevices:
    - storageClassName: "local-sc" 
      forceWipeDevicesAndDestroyAllData: false 
      volumeMode: Block
      devicePaths: 
        - /dev/disk/by-id/wwn-0x6000c296f94a2eb1ea0361a2dc4510ef
        - /dev/disk/by-id/wwn-0x6000c298464d0d48c3e72b71a54e6415
        - /dev/disk/by-id/wwn-0x6000c299f5c82f6b8a7d5a24eaee8550
 oc get localvolume -A


ODF Installation
===================
cat <<EOF | oc apply -f -
apiVersion: v1
kind: Namespace
metadata:
  labels:
    openshift.io/cluster-monitoring: "true"
  name: openshift-storage
spec: {}
EOF


Create Operator Group for ODF Operator.

cat <<EOF | oc apply -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-storage-operatorgroup
  namespace: openshift-storage
spec:
  targetNamespaces:
  - openshift-storage
EOF


cat <<EOF | oc apply -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: odf-operator
  namespace: openshift-storage
spec:
  channel: "stable-4.19"
  installPlanApproval: Automatic
  name: odf-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF


apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
  name: rbd-replica2
  namespace: openshift-storage
spec:
  replicated:
    size: 2
    requireSafeReplicaSize: false
  compressionMode: none
---
apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
  name: rbd-replica1
  namespace: openshift-storage
spec:
  replicated:
    size: 1
    requireSafeReplicaSize: false
  compressionMode: none







apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ocs-rbd-replica2
provisioner: openshift-storage.rbd.csi.ceph.com
parameters:
  clusterID: openshift-storage
  pool: rbd-replica2
  imageFormat: "2"
  imageFeatures: layering
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: openshift-storage
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/node-stage-secret-namespace: openshift-storage
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ocs-rbd-replica1
provisioner: openshift-storage.rbd.csi.ceph.com
parameters:
  clusterID: openshift-storage
  pool: rbd-replica1
  imageFormat: "2"
  imageFeatures: layering
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: openshift-storage
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/node-stage-secret-namespace: openshift-storage
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer


sample
------
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: local-sc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: lvs-fs-sc
  volumeMode: Filesystem


apiVersion: v1
kind: Pod
metadata:
  name: lvs-pod
  namespace: test
spec:
  containers:
  - name: ocs
    image: quay.io/centos/centos
    ports:
      - containerPort: 80
        name: "http-server"
    command: ["/bin/bash", "-c", "sleep 2000000000"]
    volumeMounts:
      - mountPath: /data
        name: lvs-fs-pv
  volumes:
    - name: lvs-fs-pv
      persistentVolumeClaim:
        claimName: lvs-fs-pvc




apiVersion: ocs.openshift.io/v1
kind: StorageCluster
metadata:
  name: ocs-storagecluster
  namespace: openshift-storage
spec:
  encryption:
    clusterWide: true
    enable: true
  monDataDirHostPath: /var/lib/rook
  network:
    connections:
      encryption:
        enabled: true
  resourceProfile: performance
  storageDeviceSets:
  - count: 9
    dataPVCTemplate:
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: "1" 
        storageClassName: localblock-odf
        volumeMode: Block
    name: lvs-odf
    replica: 1
  flexibleScaling: true 
  placement: 
    all:
      tolerations:
      - key: node-role.kubernetes.io/infra
        value: reserved
        effect: NoSchedule
      - key: node-role.kubernetes.io/infra
        value: reserved
        effect: NoExecute





apiVersion: local.storage.openshift.io/v1alpha1
kind: LocalVolumeDiscovery
metadata:
  name: auto-discover-devices
  namespace: openshift-local-storage


oc get localvolumediscoveryresults.local.storage.openshift.io \
  -n openshift-local-storage \
  -o jsonpath='{range .items[*]}{.metadata.name}{"\n____________________________________________\n"}{range .status.discoveredDevices[?(@.status.state=="Available")]}{"==>  "}{.path}{"-->"}{.deviceID}{"\n"}{end}{"\n"}{end}'




https://access.redhat.com/articles/6525111?extIdCarryOver=true&percmp=7015Y0000048OFsQAM&sc_cid=7013a0000026OSVAA2




apiVersion: ocs.openshift.io/v1
kind: StorageCluster
metadata:
  annotations:
    cluster.ocs.openshift.io/local-devices: "true"
    uninstall.ocs.openshift.io/cleanup-policy: delete
    uninstall.ocs.openshift.io/mode: graceful
  creationTimestamp: "2025-09-17T14:10:52Z"
  finalizers:
  - storagecluster.ocs.openshift.io
  generation: 9
  name: ocs-storagecluster
  namespace: openshift-storage
  resourceVersion: "302580582"
  uid: a2dcdce3-6e5d-4ab9-ba78-688e1aebaa71
spec:
  arbiter: {}
  enableCephTools: true
  encryption:
    clusterWide: true
    enable: true
    keyRotation:
      schedule: '@weekly'
    kms: {}
  externalStorage: {}
  flexibleScaling: true
  managedResources:
    cephBlockPools:
      defaultStorageClass: false
    cephCluster:
      monCount: 5
    cephConfig: {}
    cephDashboard: {}
    cephFilesystems:
      additionalDataPools:
      - compressionMode: none
        name: replica2
        replicated:
          size: 2
    cephNonResilientPools: {}
    cephObjectStoreUsers: {}
    cephObjectStores: {}
    cephRBDMirror: {}
    cephToolbox: {}
  monDataDirHostPath: /var/lib/rook
  multiCloudGateway:
    endpoints:
      maxCount: 10
      minCount: 3
  network:
    connections:
      encryption:
        enabled: true
    multiClusterService: {}
  nfs:
    enable: true
  nodeTopologies: {}
  resourceProfile: performance
  resources:
    noobaa-core:
      limits:
        cpu: "3"
        memory: 4Gi
      requests:
        cpu: "3"
        memory: 4Gi
    noobaa-db:
      limits:
        cpu: "3"
        memory: 4Gi
      requests:
        cpu: "3"
        memory: 4Gi
    noobaa-db-vol:
      requests:
        storage: 200Gi
    noobaa-endpoint:
      limits:
        cpu: "3"
        memory: 4Gi
      requests:
        cpu: "3"
        memory: 4Gi
  storageDeviceSets:
  - config: {}
    count: 28
    dataPVCTemplate:
      metadata: {}
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: "1"
        storageClassName: sc-local-storage-odf
        volumeMode: Block
      status: {}
    name: ocs-deviceset-sc-local-storage-odf
    placement: {}
    preparePlacement: {}
    replica: 1
    resources: {}

